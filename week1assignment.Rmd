```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(tidyverse)
library(faraway)
library(simex)
library(magrittr)
library(moments)
library(GGally)
library(knitr)
library(kableExtra)
library(caret)
library(doSNOW)
money.ball <- read_csv('C:\\Users\\Brian\\Desktop\\GradClasses\\Summer18\\621\\621week1\\moneyball-training-data.csv')
```

<div class='jumbotron'>
  <h2 class='display-3 text-uppercase'>Week 1 Assignment</h2>
  <h4 class='right text-uppercase'>By Brian Weinfeld</h4>
  <div class='clearfix'></div>
  <h5 class='right text-uppercase'>June 7th, 2018</h5>
</div>

<div class='page-header text-uppercase'>
  <h3>DATA EXPLORATION</h3>
</div>

<div class='well'>
The money ball data set contains 2276 observations with 17 integer variables representing various offensive and defensive baseball statistics collected over the past 100+ years. The below box plots demonstrates the wide range of values that the data holds. Most of the variables contain significant outliers.
</div>

```{r, warning=FALSE}
money.ball %>%
  select(-INDEX) %>%
  gather() %>%
  ggplot() +
    geom_boxplot(aes(key, value)) +
    scale_y_log10() +
    coord_flip()
```

<div class='well'>
There is a sizeable amount of missing data as well. For example, the 'hit by pitch' category is missing over 90% of its data. There was a period of time in baseball where hitting a batter with a pitch was considered a ball (and not a free base). This may be part of the reason that this statistic was not tracked.
</div>

```{r}
money.ball %>%
  map_dbl(~sum(is.na(.))/nrow(money.ball)) %>%
  kable()
```

<div class='page-header text-uppercase'>
  <h3>DATA PREPARATION</h3>
</div>

<div class='well'>
The TEAM_BASERUN_CS statistic and TEAM_BATTING_HBP statistics are missing a sizeable amount of observations. When a statistic is missing a few observation (for example, TEAM_PITCHING_SO) modifications can be made to address this issue. However, as such a large proportion are missing I think its better to ignore these columns.
</div>

```{r}
money.ball %<>%
  select(-TEAM_BASERUN_CS, -TEAM_BATTING_HBP)
```

<div class='well'>
There are 19 observations that are missing large chunks of information. This would require estimating so much of their information that I do not believe it is representative of the original team. These observations will be removed.
</div>

```{r}
money.ball %>%
  filter(TEAM_BATTING_SO == 0) %>%
  select(INDEX, TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_PITCHING_SO, TEAM_FIELDING_DP) %>%
  kable('html') %>%
  kable_styling(bootstrap_options = c('striped', 'hover'))

money.ball %<>%
  filter(TEAM_BATTING_SO != 0)
```

<div class='well'>
There are 4 observations whose values lead me to believe they are mistakes. This includes a team with 0 wins and 3 teams with certain statistics much larger than any other team. I believe these may be extrapolation errors. These observations have been removed.
</div>

```{r}
money.ball %<>%
  filter(!INDEX %in% c(1347, 2380, 1494, 1769))
```

<div class='well'>
Next, we need to address the missing values from the above noted columns. We will use the caret package to make predicted values for the missing pieces of information. Finally, we remove the index column as it is no longer needed.
</div>

```{r}
dummy.vars <- dummyVars(~ ., data = money.ball[, c(-1, -2)])
train.dummy <- predict(dummy.vars, money.ball[, c(-1, -2)])


pre.process <- preProcess(train.dummy, method='bagImpute')
imputed.data <- predict(pre.process, train.dummy)

money.ball %<>%
  mutate(TEAM_BATTING_SO = imputed.data[, 6],
         TEAM_BASERUN_SB = imputed.data[, 7],
         TEAM_PITCHING_SO = imputed.data[, 11],
         TEAM_FIELDING_DP = imputed.data[, 13]
         )

money.ball %<>%
  select(-INDEX)
```

<div class='page-header text-uppercase'>
  <h3>BUILD MODEL</h3>
</div>

<div class='alert alert-info'>
The first model we will build consists of every single predictor provided.
</div>

```{r}
l.all <- lm(TARGET_WINS ~ ., money.ball)
summary(l.all)
```

$$\widehat{WINS}=0.041\times BATTING_H + -0.017\times BATTING_{2B} + 0.067\times BATTING_{3B} + 0.051\times BATTING_{HR} + $$

$$ 0.021\times BATTING_{BB} + -0.014\times BATTING_{SO} + 0.035\times BASERUN_{SB} + 0.001\times PITCHING_{H} + $$

$$ 0.030\times PITCHING_{HR} + -0.010\times PITCHING_{BB} + 0.005\times PITCHING_{SO} + -0.030\times FIELDING_{E} + $$

$$ -0.111\times FIELDING_{DP} + 31.561$$

<div class='well'>
This model meets all the required assumptions for regression [see appendix]. However, there is much left to be desired by this model. First, it is incredibly complex, featuring 13 predictors, including 4 that are not statistically significant. Many of the predictors are highly correlated. There are a few instances of simpsons perceived paradox in the coefficients of the predictors. 'Doubles' (TEAM_BATTING_2B) has a negative slope which seems to indicate that as more doubles are hit, the number of wins decreases and 'homeruns allowed' (TEAM_PITCHING_HR) has a positive slope which seems to indicate that as more homeruns are allowed, the number of wins increases.

This model is a good baseline, but it can be improved.
</div>

<div class='alert alert-info'>
The second model will be built with backwards selection.
</div>

```{r}
l.back <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_SO + TEAM_BASERUN_SB + TEAM_FIELDING_E + TEAM_FIELDING_DP, money.ball)
summary(l.back)
```

$$\widehat{WINS}=0.042\times BATTING_H + -0.017\times BATTING_{2B} + 0.065\times BATTING_{3B} + 0.080\times BATTING_{HR} + $$
$$ 0.001\times BATTING_{BB} + -0.008\times BATTING_{SO} + 0.033\times BASERUN_{SB} + -0.027\times FIELDING_{E} + $$
$$ -0.109\times FIELDING_{DP} + 30.576$$

<div class='well'>
This model also meets all the assumptions for regression [see appendix]. This model is a marked improvement over the previous one. It has removed 4 predictors but remains just as accurate as the first model. The $R^2$ of both models is about $0.29$. This would appear to indicate that those predictors either had little to no predictive value or that they were correlated with some other predictor that does have value. This model also addresses a high leverage point that was present in the first model.

We will try to get a bit agressive with the final model.
</div>

<div class='alert alert-info'>
The third model will be built with newly created variables and provide me with some added leeway in making model decisions.
</div>

<div class='well'>
I began by combining all the positive batting statistics. Each statistic is weighted by the number of bases a player advances. Singles, walks, and stolen base are weighted 1, doubles are weighted 2, triples are weighted 3 and homeruns are weighted 4. The new observation is called TEAM_BATTING_POS. The goals is to represent the number of bases of advancement each team produces each season. It should also mitigate or remove the presence of simpsons perceived paradox.

I also removed the TEAM_FIELD_DP column. Although I had previously left it in, with over 10% of observations being imputed, it made me uncomfortable of the predictive value of the column. 

Finally, analysis found one outlying, high leverage point which was removed.
</div>

```{r}
money.ball.2 <- money.ball %>%
  mutate(TEAM_BATTING_1B = TEAM_BATTING_H - TEAM_BATTING_2B - TEAM_BATTING_3B - TEAM_BATTING_3B - TEAM_BATTING_HR,
         TEAM_BATTING_P1 = TEAM_BATTING_1B + TEAM_BATTING_BB + TEAM_BASERUN_SB,
         TEAM_BATTING_POS = TEAM_BATTING_P1 + TEAM_BATTING_2B * 2 + TEAM_BATTING_3B * 3 + TEAM_BATTING_HR * 4) %>%
  dplyr::select(-TEAM_BATTING_H, -TEAM_BATTING_1B, -TEAM_BATTING_BB, -TEAM_BATTING_P1, -TEAM_BATTING_2B, -TEAM_BATTING_3B, -TEAM_BATTING_HR, -TEAM_BASERUN_SB) %>%
  dplyr::select(-TEAM_FIELDING_DP) %>%
  filter(row_number() != 1)

l.combine <- lm(TARGET_WINS ~ TEAM_BATTING_SO + TEAM_PITCHING_BB + log(TEAM_PITCHING_SO) + TEAM_FIELDING_E +
                  TEAM_BATTING_POS, money.ball.2)
summary(l.combine)
```

$$\widehat{WINS}=0.028\times BATTING_{POS} + -0.027\times BATTING_{SO} + -0.014\times PITCHING_{BB} $$
$$+ 19.013\times log(PITCHING_{SO}) + -0.015\times FIELDING_{E} + 30.576$$

<div class='well'>
This model meets all the assumptions for regression. [see appendix]

While this model does lose some predictive power with $R^2$ of $0.265$ down from $0.29$, it may be considered a worthy tradeoff. First, it has the fewest predictors of any of the models at 5. In addition, none of the predictors fall victim to simpson's perceived paradox and thus make intuitive and logical sense. This may aid in understanding for general managers and non-statistically inclinded people. Each predictor is highly significant, indicating that we have boiled down the information to the most critical pieces of information.

There does still appears to be high collinearity in the model, however, this was present in all 3 of the created models.
</div>

```{r}
round(cor(money.ball.2[,c(-1, -3, -4)]),2) %>%
  kable()
```

<div class='page-header text-uppercase'>
  <h3>SELECT MODELS</h3>
</div>

<div class='well'>
Ultimately, I selected the third model. While it does have the least predictive power, that small loss is offset by the intuitive logic of the model and it's more simple make up. 

There are a number of issues with the dataset that should be considered. The data provided was collected for a period of time yet it lacked the time information. Thus the assumption that the residuals are independent could not be checked. This is important as the data was collected over a long period of time and the game of baseball has changed immensly in that time. Just how helpful is data from the 1800s for predicting games in 2000? I would imagine very little. 

The model was used to predict the data of the test set. A sample of the results are below.
</div>

```{r, message=FALSE}
test.set <- read_csv('C:\\Users\\Brian\\Desktop\\GradClasses\\Summer18\\621\\621week1\\moneyball-evaluation-data.csv') 

dummy.vars <- dummyVars(~ ., data = test.set[, -1])
train.dummy <- predict(dummy.vars, test.set[, -1])

pre.process <- preProcess(train.dummy, method='bagImpute')
imputed.data <- predict(pre.process, train.dummy)

test.set %<>%
  mutate(TEAM_BATTING_SO = imputed.data[, 6],
         TEAM_BASERUN_SB = imputed.data[, 7],
         TEAM_PITCHING_SO = imputed.data[, 13],
         TEAM_FIELDING_DP = imputed.data[, 15]
         ) %>%
  select(-TEAM_BASERUN_CS, -TEAM_BATTING_HBP) %>%
  mutate(TEAM_BATTING_1B = TEAM_BATTING_H - TEAM_BATTING_2B - TEAM_BATTING_3B - TEAM_BATTING_3B - TEAM_BATTING_HR,
         TEAM_BATTING_P1 = TEAM_BATTING_1B + TEAM_BATTING_BB + TEAM_BASERUN_SB,
         TEAM_BATTING_POS = TEAM_BATTING_P1 + TEAM_BATTING_2B * 2 + TEAM_BATTING_3B * 3 + TEAM_BATTING_HR * 4) %>%
  select(-TEAM_BATTING_H, -TEAM_BATTING_1B, -TEAM_BATTING_BB, -TEAM_BATTING_P1, -TEAM_BATTING_2B, -TEAM_BATTING_3B, -TEAM_BATTING_HR, -TEAM_BASERUN_SB) %>%
  select(-TEAM_FIELDING_DP, -INDEX) 

predict(l.combine, newdata = test.set, interval='prediction') %>%
  head(10) %>%
  kable('html') %>%
  kable_styling(bootstrap_options = c('striped', 'hover'))
```

<div class='well'>
In conclusion, a successfull regression was fit using 5 predictors with an $R^2$ of approximately $0.265$. This information was used to make predictions for a test set. The model is ready for deployment by the general managers however I wish to stress that without verifying the effect of collecting information over the course of a century, there are still concerns regarding the complete veracity of the information.
</div>

<div class='page-header text-uppercase'>
  <h3>Appendix</h3>
</div>

<div class='well'>
Assumptions must be validated to ensure that the regression model is valid. A light review was the first two models is followed by a more indepth review of the final, selected model.
</div>

<div class='alert alert-info'>
Model #1
</div>

```{r}
par(mfrow=c(2,2))
plot(l.all)
```

<div class='alert alert-info'>
Model #2
</div>

```{r}
par(mfrow=c(2,2))
plot(l.back)
```

<div class='alert alert-info'>
Model #3
</div>

```{r}
par(mfrow=c(2,2))
plot(l.combine)
```

```{r}
par(mfrow=c(2,3))
termplot(l.combine, partial.resid=TRUE, smooth=panel.smooth, terms=1:5)
```

<div class='well'>
The first set of plots shows that there is (mostly) constant variance in the residuals, and the data is roughly normal. We are unable to test that the residuals are independent due to a lack of dates and years for the data. We will assume independence. The second set of graphs demonstrates that each variable is linearly related to the outcome. This required a log transformation on TEAM_PITCHING_SO. It appears that there might be need for a quadradic transformation on some of the other variables however this did not greatly improve the $R^2$ value and the effect is quite subtle. I believe the appropriate decision is to leave them untransformed.
</div>